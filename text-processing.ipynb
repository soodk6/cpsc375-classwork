{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 375 Classwork - Text data - Text processing\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/soodk6/cpsc375-classwork/blob/main/text-processing.ipynb)\n",
    "\n",
    "- *Manager*: \n",
    "- *Recorder*: \n",
    "- *Presenter*: \n",
    "- *Timekeeper*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lets-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")  # default tokenizer\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Slide 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Execute these Python commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text = pd.Series([\n",
    "    \"Because I could not stop for Death -\",\n",
    "    \"He kindly stopped for me -\",\n",
    "    \"The Carriage held but just Ourselves -\",\n",
    "    \"and Immortality\",\n",
    "])\n",
    "\n",
    "text_df = (\n",
    "    text\n",
    "    .map(nltk.word_tokenize)\n",
    "    .map(lambda words: [word.lower() for word in words if word.isalnum()])\n",
    "    .explode()\n",
    "    .rename(\"word\")\n",
    "    .to_frame()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* View the output of the previous step\n",
    "\n",
    "* What changes do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Slide 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyze the tweets in file `hashcsufnew.csv`\n",
    "  - Read the CSV file\n",
    "  - Select only the text column\n",
    "  - Make it into a tidytext format\n",
    "    * *Hint*: Use `.map(lambda text: text.replace(\"â€™\", \"'\"))` before tokenizing.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Count word occurrences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Which are the most common words?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Which are the most common hashtags?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Slide 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Working with the CSUF tweets\n",
    " \n",
    "  - Keep only word occurrences > 200 (query)\n",
    "  - Save your result in some object\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Working with the CSUF tweets\n",
    "\n",
    "  - Draw a bar chart of the word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lets_plot import *\n",
    "\n",
    "LetsPlot.setup_html()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Slide 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create any word cloud (with your own words and word counts)\n",
    "\n",
    "Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "cloud = WordCloud()\n",
    "image = cloud.generate_from_frequencies({\"Hello\": 50, \"how\": 40, \"are\": 20, \"you\": 40})\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a word cloud from the CSUF tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Slide 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Execute these Python commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_df = pd.DataFrame(dict(word=nltk.corpus.stopwords.words(\"english\")))\n",
    "\n",
    "(\n",
    "    pd.merge(text_df, stopwords_df, how=\"left\", indicator=True)\n",
    "    .query('_merge == \"left_only\"')\n",
    "    .filter(text_df.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Working with the CSUF tweets\n",
    "  - Remove stop words (anti-join)\n",
    "  - Create a word cloud from these words\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Slide 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Working with the CSUF tweets\n",
    "  - After removing stop words\n",
    "    * Stem the words\n",
    "  - After saving word occurrences > 200 into some object\n",
    "    * Create a word cloud from these words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "murach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
